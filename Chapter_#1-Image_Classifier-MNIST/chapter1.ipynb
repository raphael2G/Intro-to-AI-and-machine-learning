{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b58a8a-5b61-4431-a6db-3b97782929f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T14:07:47.281015Z",
     "iopub.status.busy": "2022-12-02T14:07:47.280618Z",
     "iopub.status.idle": "2022-12-02T14:08:00.594690Z",
     "shell.execute_reply": "2022-12-02T14:08:00.593192Z",
     "shell.execute_reply.started": "2022-12-02T14:07:47.280933Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Download dependcies\n",
    "%pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef1cfad-534b-47b4-9bdd-db39cb5ea27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T14:08:29.130735Z",
     "iopub.status.busy": "2022-12-02T14:08:29.129729Z",
     "iopub.status.idle": "2022-12-02T14:08:35.860717Z",
     "shell.execute_reply": "2022-12-02T14:08:35.855011Z",
     "shell.execute_reply.started": "2022-12-02T14:08:29.130703Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Sequential, losses, metrics, layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93e167-476c-46f5-b726-d03d9434fb53",
   "metadata": {},
   "source": [
    "1. Get the data\n",
    "2. Create the neural network (AI Model)\n",
    "3. Train the model\n",
    "4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2093532-45bc-4f96-af4c-863e3d43506d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T14:08:48.678989Z",
     "iopub.status.busy": "2022-12-02T14:08:48.677646Z",
     "iopub.status.idle": "2022-12-02T14:08:48.780738Z",
     "shell.execute_reply": "2022-12-02T14:08:48.779740Z",
     "shell.execute_reply.started": "2022-12-02T14:08:48.678935Z"
    }
   },
   "outputs": [],
   "source": [
    "# download dataset from tfds\n",
    "(train_dataset, test_dataset), info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19416a4b-1fc0-42a5-b788-45f5162b5b01",
   "metadata": {},
   "source": [
    "1. Creating training and testing dataset\n",
    "\n",
    "In this section we use tensorflow datasets to download the Mnist dataset of thousands of handwritten digits.\n",
    "\n",
    "We create distince training and testing datasets for the purpose of training the model, and subsequenty \n",
    "evaluating the dataset. \n",
    "\n",
    "We will use code to view the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c0f6d8-c120-4f47-a2f2-01f14a55b9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T14:09:00.376738Z",
     "iopub.status.busy": "2022-12-02T14:09:00.375202Z",
     "iopub.status.idle": "2022-12-02T14:09:01.069614Z",
     "shell.execute_reply": "2022-12-02T14:09:01.068549Z",
     "shell.execute_reply.started": "2022-12-02T14:09:00.376697Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 14:09:00.454003: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_27174\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_27174_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_27174_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27174_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_27174_row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_27174_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27174_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_27174_row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGOyAc/5KJlxyjIv+/TPEJan9798HWRgH3YhQBoZHj3HpfP/vVxQuOYF//54ieGjGNjEwXMalkeHbv3+eeCTfseAy1oCVYeofXBp3/f8lgUtO/su/azhtnPLvXwJOycv//uGU0//5bx1OySP//hngkuN5+u8tG4oIkj/VJBmO/8Il6cvAMBunlSIvX3DjlKQmAACHtTHZmy2LVAAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_27174_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27174_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_27174_row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nM3QvyuEARzH8feVniSFiTBcKf8A85ESNqwkdbeY5NdmY/UXiM0z+Ad0SXZ1g0vJjw0Xi86pc13eD8NleJ47q3zG76tv3x/wJxk+jQ7bf8NldT9obdNl1fWW1nGh6mtLPIm0oJVWlvuIvOvMWx1qtqWa0U2aULNNNnCtT+MQapi0waK6CoR6mcS8Wuhq4Fqj1PZjU5NQnX0DUine433dD1qZBwjOrM/EsVc9AmCj6c5MWT8XADjX2mgMi+otABN1k0/YVncAFu/VLWLbPgNBduRxLBMQHe/FZ+Zs5EtLm8kP9F81MHrZTScNelZK6sFcXzP9o3wDadaKxdoXqEQAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_27174_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27174_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_27174_row3_col0\" class=\"data row3 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA40lEQVR4nGNgGJpg//8OdCEWKM2obvgv/++6/zcZnJQebPuNqkjvLxI4IIgiJ3/v79/3b//9/fvv7993f/9NQzE2TZ6hc8J3JwYGBgaGK7cYeJE12n79+1cCxlH9+/cVB5LOlxy/pryHSUYyMO78gSR5W/vzU7gxfAz/cfq36fvfDw445Fr+/P3bg12KMebb37+7WbDKKSz89/fvNRmscjpb//79u0YBq5z0yb9//2bhcEvXv78fs1ixyzX//PsuHYc+gbvwAMcEmX//3kFzJxOc9YCRoesJLp3sx9+p4JIjGQAAnrpmBs0pxioAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_27174_row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27174_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_27174_row4_col0\" class=\"data row4 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABRUlEQVR4nM2RMUgCcRTGvwvFjjiuhqgIpG4Kg8QaQi6aWoo2JXAot6ZokxwdGxybWjJoapLCQRoaJBKkoIJuKDc7DAruIEmH967hvPJ/Nkdv+vh+fI//+/7Afxglyy+qK6UeW1MSg5p2twVp4lUMhGYuLSYiJiIec72AlzqNAVf1klUGYLaF3BqzXdQBbLJtc0Fgsx26ngQARA72miQLMEU08qM/PDkAAIgBC56TQV58apSZ+ex4Pw6k2fQdHly9fSYi7phmi6pRz/4uQZleVyUnPSo5wEPmAv2zYlFto9BgS+tnuRZXNGCJec6PgiWmExXALt8HRDS+U3n6zMkAhgxOCUg+YqJyEgAQp4bayxZr7OS7HYXfebtru8sT8w4MJQwAena4fihsjRjE9Ob+Zftc8ZUQWtan5KTkPN40i9VfCvi7+QIpz4HjFNztwwAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_27174_row4_col1\" class=\"data row4 col1\" >8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
       "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
       "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      0\n",
       "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      7\n",
       "4  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.as_dataframe(train_dataset.take(5), info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a4dfc",
   "metadata": {},
   "source": [
    "At https://knowyourdata-tfds.withgoogle.com/#tab=STATS&dataset=mnist you can examine the MNIST dataset with more options. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a0caf-28e8-46e8-845e-a3c1b188ad2f",
   "metadata": {},
   "source": [
    "2. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab1b6ce7-bb78-457d-8a83-7281d16483b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T14:39:10.200531Z",
     "iopub.status.busy": "2022-12-02T14:39:10.200113Z",
     "iopub.status.idle": "2022-12-02T14:39:10.351469Z",
     "shell.execute_reply": "2022-12-02T14:39:10.350469Z",
     "shell.execute_reply.started": "2022-12-02T14:39:10.200506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(28, 28, 1)))\n",
    "model.add(layers.Rescaling(scale=1./255))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=64))\n",
    "model.add(layers.Dense(units=10))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=metrics.SparseCategoricalAccuracy()\n",
    "             )\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb23a4-a8f1-4dca-ab0e-4ee3029351f2",
   "metadata": {},
   "source": [
    "The model is composed of a few layers. We will break them down here. \n",
    "\n",
    "The first layer is the input layer. This tell the model what size input to expect. While this is not striclty necessary in this \n",
    "circumstance, it makes the idea of input shape more understandable. \n",
    "\n",
    "The second layer is a rescaling layer. This layer takes all of the datapoints in scales them (linearly) between 0 and 1. \n",
    "Rescaling the domain (data) between 0 and 1 increases model convergence. The number 255 was chosen based on the range of \n",
    "possible datapoints being between 0 and 255. Example: (0, 255) / 255 --> (0/255, 255/255) = (0, 1)\n",
    "\n",
    "The third layer is a flattening layer. Images are 2 dimensional (arguable with idea of channels, but irrelevant to the purpose of\n",
    "this text). Our feed-forward multilayer perceptron (MLP) can only take 1 dimensional data. Because of this, we need a way to convert\n",
    "the 2D image to 1D. This can be done by flattening the image. By taking every row of pixels and stacking them next to \n",
    "eachother (as displayed in the image below), you are able to turn 2D data into 1D data. The drawback of this method is that it \n",
    "destroys all spatial continuity. Imagine trying to identfiy an image that is flat. It's pretty difficult! This issue was solved\n",
    "with the introduction of the CNN based off of the human visual system. \n",
    "\n",
    "The fourth layer is the first hidden layer. This is where the neural network first begins to influence the data. The other layers \n",
    "are simply data processing. There can be an arbitrary amount of nodes in this layer, but standard practice is to chose an amount\n",
    "of nodes in multiples of twos (Ex. 32, 64, 128, 256..)\n",
    "\n",
    "The fifth layer is the output layer of the model. This layer is required to have the same amout of nodes as the amount of classes. \n",
    "Each output represents a different confidence for each class. For example, an image classifier looking to determine\n",
    "the differences between Cats and Dogs will have 2 outputs. The may be the confidence the model thinks it's a Cat, and the second\n",
    "is the confidence the model think it's a Dog. Ex. [-1.523, 5.2715]. This output is what is known as logits. The index of the highest\n",
    "number in the output is the models prediction. These logits can be converted to percentage confidence throuhg a softmax activation\n",
    "function. Ex. [0.13, 0.87] The model is 13% confident the input is a cat, and 87% confident the model is a dog. In order to\n",
    "achieve percentages in this form, a softmax activation funciton is necessary. Without it, the model will\n",
    "output logits which are NOT a percentage confidence, but instead a relative percentage. Ex. [-1.523, 5.2715]. These logits are then \n",
    "converted to percentage confidence through the softmax activation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14417fcd-5c2d-4e81-bf14-b7fe1adcceb5",
   "metadata": {},
   "source": [
    "<img src=\"https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/73_blog_image_1.png\" alt=\"Flattened Image\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f358525-c359-4ed3-958b-5be588fd8003",
   "metadata": {},
   "source": [
    "3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24163def-49d3-4d86-827e-4bc9ece7e295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T14:39:13.586947Z",
     "iopub.status.busy": "2022-12-02T14:39:13.586162Z",
     "iopub.status.idle": "2022-12-02T14:40:04.373506Z",
     "shell.execute_reply": "2022-12-02T14:40:04.372160Z",
     "shell.execute_reply.started": "2022-12-02T14:39:13.586915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.3896 - sparse_categorical_accuracy: 0.8899\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.2916 - sparse_categorical_accuracy: 0.9190\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 0.2796 - sparse_categorical_accuracy: 0.9230\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.2729 - sparse_categorical_accuracy: 0.9249\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.2684 - sparse_categorical_accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01541ee6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset.batch(64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f0b26",
   "metadata": {},
   "source": [
    "4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e8e017d-dbc3-4986-9d13-67c0fb49cded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:01:24.841124Z",
     "iopub.status.busy": "2022-12-02T10:01:24.840306Z",
     "iopub.status.idle": "2022-12-02T10:01:25.020865Z",
     "shell.execute_reply": "2022-12-02T10:01:25.020100Z",
     "shell.execute_reply.started": "2022-12-02T10:01:24.841087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d4682\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4682_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_d4682_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4682_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4682_row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_d4682_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_dataset.take(1)\n",
    "tfds.as_dataframe(sample, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6287854e-8537-4469-8ca1-5850dd02dc38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T10:03:49.061660Z",
     "iopub.status.busy": "2022-12-02T10:03:49.061309Z",
     "iopub.status.idle": "2022-12-02T10:03:49.086638Z",
     "shell.execute_reply": "2022-12-02T10:03:49.085826Z",
     "shell.execute_reply.started": "2022-12-02T10:03:49.061631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:  tf.Tensor(\n",
      "[[-4.722601    0.91229534 -0.5110078  -1.4698832   6.3419003   1.2759331\n",
      "   1.2624689  -1.1037034   2.5184054   2.4678671 ]], shape=(1, 10), dtype=float32)\n",
      "Prediction:  4\n",
      "Label:  tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in sample: \n",
    "    image = tf.reshape(x, (1, 28, 28, 1))\n",
    "    output = model(image)\n",
    "    print('Model Output: ', output)\n",
    "    print('Prediction: ', np.argmax(output.numpy()))\n",
    "    print('Label: ', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
